{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Entity-Unit Extraction and Assignment**\n",
        "\n",
        "This code performs the extraction and assignment of entity values and their units from text, specifically for attributes like weight, volume, voltage, and wattage. Here's how it works:\n",
        "\n",
        "Libraries:\n",
        "\n",
        "It uses spaCy for natural language processing and tokenization, re for regex-based matching, and pandas for CSV file handling.\n",
        "Entity-Unit Map:\n",
        "\n",
        "A dictionary (entity_unit_map) maps entity types (e.g., item weight, voltage) to a set of potential units associated with each (e.g., grams, kilograms for weight).\n",
        "\n",
        "Text Extraction:\n",
        "\n",
        "The function extract_and_detect_first processes each text field, using regex to match numbers followed by a valid unit. It checks whether the detected unit belongs to the set defined for that entity type.\n",
        "\n",
        "Value Assignment:\n",
        "\n",
        "The assign_values function assigns the detected value and unit to their respective columns in the correct format (e.g., \"3.75 pounds\"). If multiple units are found, it uses the first one.\n",
        "\n",
        "CSV Processing:\n",
        "\n",
        "The process_csv function reads a CSV file, processes the data row by row, extracts entity values for specific columns (like weight and volume), and then saves the updated file.\n",
        "\n",
        "Usage:\n",
        "\n",
        "You run the process_csv function with a file path to process the CSV and save an updated version."
      ],
      "metadata": {
        "id": "_cuf5gq0_5uS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnCVtOFt_EpE"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "# Load spaCy's small English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Entity-unit map\n",
        "entity_unit_map = {\n",
        "    'item_weight': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n",
        "    'maximum_weight_recommendation': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n",
        "    'voltage': {'kilovolt', 'millivolt', 'volt'},\n",
        "    'wattage': {'kilowatt', 'watt'},\n",
        "    'item_volume': {'centilitre', 'cubic foot', 'cubic inch', 'cup', 'decilitre', 'fluid ounce', 'gallon', 'imperial gallon', 'litre', 'microlitre', 'millilitre', 'pint', 'quart'}\n",
        "}\n",
        "\n",
        "# Function to extract and detect the first unit for each quantity\n",
        "def extract_and_detect_first(text, entity_type):\n",
        "    doc = nlp(text)\n",
        "    detected_units = {}\n",
        "\n",
        "    # Check if the entity type is in the map\n",
        "    if entity_type not in entity_unit_map:\n",
        "        return detected_units\n",
        "\n",
        "    # Iterate over tokens to extract numbers and their associated units\n",
        "    for token in doc:\n",
        "        if re.match(r\"[\\d.]+\", token.text):  # Match numbers\n",
        "            next_token = doc[token.i + 1] if token.i + 1 < len(doc) else None\n",
        "            if next_token and next_token.text in entity_unit_map.get(entity_type, {}):  # Match unit\n",
        "                unit = next_token.text\n",
        "                if unit not in detected_units:\n",
        "                    detected_units[unit] = token.text  # Store number and unit together in correct order\n",
        "\n",
        "    return detected_units\n",
        "\n",
        "# Function to assign extracted values based on entity types\n",
        "def assign_values(row):\n",
        "    detected_values = {}\n",
        "    for entity_type, units in entity_unit_map.items():\n",
        "        text = str(row.get(entity_type, ''))\n",
        "        detected_units = extract_and_detect_first(text, entity_type)\n",
        "        if detected_units:\n",
        "            # Correct the format: use number and then unit (e.g., \"3.75 pound\")\n",
        "            detected_values[entity_type] = next(iter(detected_units.items()))  # Get the first detected unit\n",
        "\n",
        "    # Assign detected values to the corresponding columns in correct format\n",
        "    for entity_type, (unit_value, unit_name) in detected_values.items():\n",
        "        row[entity_type] = f\"{unit_name} {unit_value}\"  # Correct order: number followed by unit\n",
        "\n",
        "    return row\n",
        "\n",
        "# Function to process CSV file and update relevant columns\n",
        "def process_csv(file_path):\n",
        "    # Read the CSV file into a pandas DataFrame\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Process each row in the DataFrame\n",
        "    for index, row in df.iterrows():\n",
        "        # Extract and assign values for all quantities\n",
        "        updated_row = assign_values(row)\n",
        "\n",
        "        # Update the DataFrame with the new values\n",
        "        df.loc[index] = updated_row\n",
        "\n",
        "    # Save the updated DataFrame back to the CSV file or create a new file\n",
        "    df.to_csv('updated_file.csv', index=False)\n",
        "    print(\"CSV file processed and updated.\")\n",
        "\n",
        "# Example usage\n",
        "file_path = r\"C:\\Users\\MYPC\\AMAZON_ML\\student_resource 3\\merged_output.csv\" # Replace with your CSV file path\n",
        "process_csv(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Measurement Extraction and Conversion**\n",
        "\n",
        "This code processes text fields to extract and convert size measurements (e.g., height, width, depth) from units like centimeters, millimeters, meters, inches, and feet. It converts all values to millimeters for uniformity.\n",
        "\n",
        "Libraries:\n",
        "\n",
        "It uses spaCy for text tokenization, re for regex matching, and pandas for CSV processing.\n",
        "\n",
        "Conversion Factors:\n",
        "\n",
        "A dictionary (conversion_factors) stores conversion ratios for different units (e.g., 1 centimeter = 10 millimeters, 1 foot = 304.8 millimeters).\n",
        "\n",
        "Priority of Units:\n",
        "\n",
        "A priority list (unit_priority) defines which unit should take precedence when multiple units are detected (e.g., centimeters before inches).\n",
        "\n",
        "Text Extraction and Conversion:\n",
        "\n",
        "The function extract_and_convert extracts numerical values from text and multiplies them by the appropriate conversion factor to convert them to millimeters. It sorts these values by size (in millimeters).\n",
        "\n",
        "Value Assignment:\n",
        "\n",
        "The assign_values function assigns the top three extracted values to height, width, and depth based on size, ensuring the largest is assigned to height, the second largest to width, and so on. If fewer than three values are found, the assignments are made accordingly.\n",
        "\n",
        "CSV Processing:\n",
        "\n",
        "The process_csv function reads a CSV file, processes each row, extracts size measurements (e.g., width), and assigns the converted values to height, width, and depth columns. The results are saved in a new CSV file.\n",
        "\n",
        "Usage:\n",
        "\n",
        "This function is executed by specifying the CSV file path, which will be updated with the new extracted and converted measurements."
      ],
      "metadata": {
        "id": "_dOGWOSZAahq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "# Load spaCy's small English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Conversion factors for units to millimeters\n",
        "conversion_factors = {\n",
        "    'centimetre': 10,          # Centimeter to millimeter\n",
        "    'millimetre': 1,           # Millimeter as base\n",
        "    'metre': 1000,             # Meter to millimeter\n",
        "    'inch': 25.4,              # Inch to millimeter\n",
        "    'foot': 304.8              # Foot to millimeter\n",
        "}\n",
        "\n",
        "# Define the priority list for units\n",
        "unit_priority = ['centimetre', 'inch', 'millimetre', 'foot','metre']\n",
        "\n",
        "# Function to extract and convert quantities from text\n",
        "# def extract_and_convert(text):\n",
        "#     doc = nlp(text)\n",
        "#     measurements = []\n",
        "#     detected_unit = None\n",
        "\n",
        "#     # Iterate over tokens to extract numbers and their associated units\n",
        "#     for token in doc:\n",
        "#         if re.match(r\"[\\d.]+\", token.text):  # Match numbers\n",
        "#             next_token = doc[token.i + 1] if token.i + 1 < len(doc) else None\n",
        "#             if next_token and next_token.text in conversion_factors:  # Match unit\n",
        "#                 unit = next_token.text\n",
        "\n",
        "#                 # Check if the unit is of higher priority or same as already detected one\n",
        "#                 if detected_unit is None or unit_priority.index(unit) < unit_priority.index(detected_unit):\n",
        "#                     # If a higher priority unit is detected, reset the measurements list\n",
        "#                     detected_unit = unit\n",
        "#                     measurements = []\n",
        "\n",
        "#                 if unit == detected_unit:  # Only process the highest-priority unit\n",
        "#                     number = float(token.text)\n",
        "#                     mm_value = number * conversion_factors[unit]\n",
        "#                     measurements.append((number, unit, mm_value))\n",
        "\n",
        "#     # Sort the measurements by their millimeter value in descending order\n",
        "#     sorted_measurements = sorted(measurements, key=lambda x: x[2], reverse=True)\n",
        "\n",
        "#     return sorted_measurements\n",
        "\n",
        "def extract_and_convert(text):\n",
        "    doc = nlp(text)\n",
        "    measurements = []\n",
        "\n",
        "    for token in doc:\n",
        "        if re.match(r\"[\\d.]+\", token.text):  # Match numbers\n",
        "            next_token = doc[token.i + 1] if token.i + 1 < len(doc) else None\n",
        "            if next_token and next_token.text in conversion_factors:  # Match unit\n",
        "                unit = next_token.text\n",
        "                number = float(token.text)\n",
        "                mm_value = number * conversion_factors[unit]\n",
        "                measurements.append((number, unit, mm_value))\n",
        "\n",
        "    # Sort the measurements by their millimeter value in descending order\n",
        "    sorted_measurements = sorted(measurements, key=lambda x: x[2], reverse=True)\n",
        "\n",
        "    return sorted_measurements\n",
        "\n",
        "\n",
        "# Function to assign extracted values based on count\n",
        "# def assign_values(extracted_values, entity_name):\n",
        "#     # Initialize with None for height, width, and depth\n",
        "#     height, width, depth = None, None, None\n",
        "\n",
        "#     if len(extracted_values) >= 3:\n",
        "#         # Assign largest to height, second largest to width, and third to depth\n",
        "#         height = f\"{extracted_values[0][0]} {extracted_values[0][1]}\"\n",
        "#         width = f\"{extracted_values[1][0]} {extracted_values[1][1]}\"\n",
        "#         depth = f\"{extracted_values[2][0]} {extracted_values[2][1]}\"\n",
        "#     elif len(extracted_values) == 2:\n",
        "#         # Assign largest to height, second to width, and empty the width cell\n",
        "#         height = f\"{extracted_values[0][0]} {extracted_values[0][1]}\"\n",
        "#         width = f\"{extracted_values[1][0]} {extracted_values[1][1]}\"\n",
        "#         depth = \"\"\n",
        "#     elif len(extracted_values) == 1:\n",
        "#         # Check the entity_name and assign the only value based on that\n",
        "#         if \"height\" in entity_name.lower():\n",
        "#             height = f\"{extracted_values[0][0]} {extracted_values[0][1]}\"\n",
        "#             width = \"\"\n",
        "#             depth = \"\"\n",
        "#         elif \"width\" in entity_name.lower():\n",
        "#             width = f\"{extracted_values[0][0]} {extracted_values[0][1]}\"\n",
        "#             height = \"\"\n",
        "#             depth = \"\"\n",
        "#         elif \"depth\" in entity_name.lower():\n",
        "#             depth = f\"{extracted_values[0][0]} {extracted_values[0][1]}\"\n",
        "#             height = \"\"\n",
        "#             width = \"\"\n",
        "\n",
        "#     return height, width, depth\n",
        "\n",
        "def assign_values(extracted_values, entity_name):\n",
        "    # Initialize with None for height, width, and depth\n",
        "    height, width, depth = None, None, None\n",
        "\n",
        "    # Sort extracted values by their millimeter value in descending order\n",
        "    sorted_values = sorted(extracted_values, key=lambda x: x[2], reverse=True)\n",
        "\n",
        "    # Assign top three values to height, width, and depth\n",
        "    if len(sorted_values) >= 3:\n",
        "        height = f\"{sorted_values[0][0]} {sorted_values[0][1]}\"\n",
        "        width = f\"{sorted_values[1][0]} {sorted_values[1][1]}\"\n",
        "        depth = f\"{sorted_values[2][0]} {sorted_values[2][1]}\"\n",
        "    elif len(sorted_values) == 2:\n",
        "        height = f\"{sorted_values[0][0]} {sorted_values[0][1]}\"\n",
        "        width = f\"{sorted_values[1][0]} {sorted_values[1][1]}\"\n",
        "        depth = \"\"\n",
        "    elif len(sorted_values) == 1:\n",
        "        # Check the entity_name and assign the only value based on that\n",
        "        if \"height\" in entity_name.lower():\n",
        "            height = f\"{sorted_values[0][0]} {sorted_values[0][1]}\"\n",
        "            width = \"\"\n",
        "            depth = \"\"\n",
        "        elif \"width\" in entity_name.lower():\n",
        "            width = f\"{sorted_values[0][0]} {sorted_values[0][1]}\"\n",
        "            height = \"\"\n",
        "            depth = \"\"\n",
        "        elif \"depth\" in entity_name.lower():\n",
        "            depth = f\"{sorted_values[0][0]} {sorted_values[0][1]}\"\n",
        "            height = \"\"\n",
        "            width = \"\"\n",
        "\n",
        "    return height, width, depth\n",
        "\n",
        "# Function to process CSV file and update height, width, and depth columns\n",
        "def process_csv(file_path):\n",
        "    # Read the CSV file into a pandas DataFrame\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Iterate through each row and process the width column\n",
        "    for index, row in df.iterrows():\n",
        "        # Extract the width column text\n",
        "        text = str(row['width'])\n",
        "\n",
        "        # Extract and convert the values using the provided function\n",
        "        extracted_values = extract_and_convert(text)\n",
        "\n",
        "        # Assign the extracted values to height, width, depth based on the logic\n",
        "        entity_name = row.get('entity_name', '')  # Assuming there is an 'entity_name' column\n",
        "        height, width, depth = assign_values(extracted_values, entity_name)\n",
        "\n",
        "        # Update the DataFrame with the new values\n",
        "        if height is not None:\n",
        "            df.at[index, 'height'] = height\n",
        "        if width is not None:\n",
        "            df.at[index, 'width'] = width\n",
        "        if depth is not None:\n",
        "            df.at[index, 'depth'] = depth\n",
        "\n",
        "    # Save the updated DataFrame back to the CSV file or create a new file\n",
        "    df.to_csv('updated_file1.csv', index=False)\n",
        "    print(\"CSV file processed and updated.\")\n",
        "\n",
        "# Example usage\n",
        "file_path = r\"E:\\ML_challenge_DATASET\\TEST\\Check_detection\\DETECTION_2\\Merged_OUTPUT.csv\"  # Replace with your CSV file path\n",
        "process_csv(file_path)"
      ],
      "metadata": {
        "id": "gBN0-2SC_W9n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}