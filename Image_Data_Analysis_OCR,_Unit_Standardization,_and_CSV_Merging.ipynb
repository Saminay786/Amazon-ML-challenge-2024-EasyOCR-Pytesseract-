{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**1. Extract Text from Images Using EasyOCR and Save Results to CSV:**\n",
        "\n",
        "*Libraries Used: cv2, numpy, easyocr, os, pandas, torch.*\n",
        "Process:\n",
        "1. Images are loaded from a folder using os.listdir().\n",
        "2. Text is extracted from each image using EasyOCR, a deep learning-based OCR library that supports GPU acceleration via CUDA.\n",
        "3. The recognize_text() function uses EasyOCR to extract text from each image.\n",
        "4. The extracted text is saved in a CSV file along with the corresponding image names. The text is only saved if the recognition probability is above 0.2.\n",
        "5. The GPU (CUDA) is used for text recognition if available, otherwise, the CPU is used.\n",
        "6. The resulting CSV contains two columns: Image Name and Detected Text."
      ],
      "metadata": {
        "id": "Fld5e8R9xhg4"
      },
      "id": "Fld5e8R9xhg4"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MWGZlDeqzp50"
      },
      "id": "MWGZlDeqzp50",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c166c45-3746-496c-8df4-74605f947fc2",
      "metadata": {
        "id": "6c166c45-3746-496c-8df4-74605f947fc2"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import easyocr\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "# Extracting the path of images one by one in the form of list\n",
        "img_folder_path = r\"E:\\ML_challenge_DATASET\\TEST\\Test_data\\Folder_10\"\n",
        "create_path = lambda f: os.path.join(img_folder_path, f)\n",
        "test_image_files = os.listdir(img_folder_path)\n",
        "\n",
        "# Recognize text function using EasyOCR with CUDA support\n",
        "def recognize_text(img_path, reader):\n",
        "    '''Loads an image and recognizes text using GPU if available.'''\n",
        "    return reader.readtext(img_path)\n",
        "\n",
        "# Extracting text from all images in the folder and saving to a CSV\n",
        "def save_ocr_results_to_csv(folder_path, csv_filename):\n",
        "    '''Detects text from all images in a folder and saves the results in a CSV.'''\n",
        "\n",
        "    data = []  # List to hold image names and their detected texts\n",
        "\n",
        "    # Check if CUDA is available\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = 'GPU' if use_cuda else 'CPU'\n",
        "    print(f\"Using {device} for computation.\")\n",
        "\n",
        "    # Create the EasyOCR reader with GPU support if available\n",
        "    reader = easyocr.Reader(['en'], gpu=use_cuda)  # Enable GPU if CUDA is available\n",
        "\n",
        "    try:\n",
        "        # Loop through all image files in the folder\n",
        "        for img_file in os.listdir(folder_path):\n",
        "            # Get the full image path\n",
        "            img_path = os.path.join(folder_path, img_file)\n",
        "\n",
        "            if img_file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
        "                print(f\"Processing image: {img_file}\")\n",
        "\n",
        "                # Perform OCR on the image\n",
        "                result = recognize_text(img_path, reader)\n",
        "\n",
        "                # Combine all recognized text in the image\n",
        "                detected_text = \" \".join([text for (_, text, prob) in result if prob >= 0.2])\n",
        "\n",
        "                # Append the image name and detected text to the data list\n",
        "                data.append([img_file, detected_text])\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error encountered: {e}\")\n",
        "\n",
        "    finally:\n",
        "        # Convert the data to a DataFrame and save it to a CSV file\n",
        "        df = pd.DataFrame(data, columns=['Image Name', 'Detected Text'])\n",
        "        df.to_csv(csv_filename, index=False)\n",
        "        print(f\"Partial results saved to {csv_filename}\")\n",
        "\n",
        "# Specify the folder containing images and the CSV file to save the results\n",
        "csv_output_path = r\"E:\\ML_challenge_DATASET\\TEST\\Test_data\\Folder10_OCR.csv\"\n",
        "\n",
        "# Call the function to process all images and save results to CSV\n",
        "save_ocr_results_to_csv(img_folder_path, csv_output_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Extract and Standardize Units from Detected Text:**\n",
        "\n",
        "*Libraries Used: pandas, re.*\n",
        "Process:\n",
        "1. A dictionary, entity_unit_map, defines unit types (e.g., length, weight, volume) and their possible variations (e.g., \"cm\", \"mm\", \"kg\").\n",
        "2. A unit_conversion_map converts unit abbreviations or variants into a standardized form.\n",
        "3. The correct_o_to_0() function corrects errors where the character 'O' is mistakenly used in numeric values.\n",
        "4. The extract_numbers_with_units() function extracts numbers followed by units (e.g., \"20 kg\") from the detected text.\n",
        "5. A CSV with image names and detected text is read, and for each row, unit-specific information (e.g., width, weight, height) is extracted and standardized into the desired units.\n",
        "6. The results are saved in a new CSV file with the standardized values."
      ],
      "metadata": {
        "id": "SxBgBFWtxgjR"
      },
      "id": "SxBgBFWtxgjR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "722c3f7d-48b4-4c14-9f9f-ba5bf1f6eba3",
      "metadata": {
        "id": "722c3f7d-48b4-4c14-9f9f-ba5bf1f6eba3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Define the unit map\n",
        "entity_unit_map = {\n",
        "    \"width\": {\"centimetre\", \"centimeter\", \"centimeters\", \"cm\", \"foot\", \"ft\", \"millimetre\", \"millimeter\", \"mm\", \"metre\", \"meter\", \"meters\", \"m\", \"inch\", \"in\", \"inches\", \"yard\", \"yd\", '\"', \"'\", \"CM\", \"Inches\"},\n",
        "    \"depth\": {\"centimetre\", \"centimeter\", \"centimeters\", \"cm\", \"foot\", \"ft\", \"millimetre\", \"millimeter\", \"mm\", \"metre\", \"meter\", \"meters\", \"m\", \"inch\", \"in\", \"inches\", \"yard\", \"yd\", '\"', \"'\", \"CM\", \"Inches\"},\n",
        "    \"height\": {\"centimetre\", \"centimeter\", \"centimeters\", \"cm\", \"foot\", \"ft\", \"FEET\", \"millimetre\", \"millimeter\", \"mm\", \"metre\", \"meter\", \"meters\", \"m\", \"inch\", \"in\", \"inches\", \"yard\", \"yd\", '\"',\"'\", \"CM\", \"Inches\"},\n",
        "    \"item_weight\": {\"milligram\", \"mg\", \"kilogram\", \"kg\", \"microgram\", \"µg\", \"gram\", \"g\", \"ounce\", \"oz\", \"ton\", \"pound\", \"lb\", \"LBS\", \"lbs\", \"MG\", \"mG\"},\n",
        "    \"maximum_weight_recommendation\": {\"milligram\", \"mg\", \"kilogram\", \"kg\", \"microgram\", \"µg\", \"gram\", \"g\", \"ounce\", \"oz\", \"ton\", \"pound\", \"lb\", \"lbs\", \"LBS\", \"mG\", \"MG\"},\n",
        "    \"voltage\": {\"millivolt\", \"mv\", \"kilovolt\", \"kv\", \"volt\", \"v\", \"MV\", \"MV\"},\n",
        "    \"wattage\": {\"kilowatt\", \"kw\", \"watt\", \"w\", \"Watt\", \"WATT\", \"KW\"},\n",
        "    \"item_volume\": {\"cubic foot\", \"ft³\", \"microlitre\", \"µl\", \"cup\", \"Cup\", \"fluid ounce\", \"fl oz\", \"centilitre\", \"cl\", \"imperial gallon\", \"gal\", \"pint\", \"pt\", \"decilitre\", \"dl\", \"litre\", \"l\", \"millilitre\", \"ml\", \"quart\", \"qt\", \"cubic inch\", \"in³\", \"gallon\", \"gal\"},\n",
        "}\n",
        "\n",
        "# Define the unit conversion map\n",
        "unit_conversion_map = {\n",
        "    \"cm\": \"centimetre\", \"CM\": \"centimetre\", \"Cm\": \"centimetre\", \"cM\": \"centimetre\",\n",
        "    \"ft\": \"foot\", \"FT\": \"foot\", \"Ft\": \"foot\", \"fT\": \"foot\", \"FEET\": \"foot\",\n",
        "    \"m\": \"metre\", \"M\": \"metre\",\n",
        "    \"mm\": \"millimetre\", \"MM\": \"millimetre\", \"Mm\": \"millimetre\", \"mM\": \"millimetre\",\n",
        "    \"kg\": \"kilogram\", \"KG\": \"kilogram\", \"Kg\": \"kilogram\", \"kG\": \"kilogram\",\n",
        "    \"µg\": \"microgram\", \"µG\": \"microgram\", \"Mg\": \"milligram\", \"MG\": \"milligram\",\n",
        "    \"g\": \"gram\", \"G\": \"gram\",\n",
        "    \"oz\": \"ounce\", \"OZ\": \"ounce\", \"Oz\": \"ounce\", \"oZ\": \"ounce\",\n",
        "    \"lb\": \"pound\", \"lbs\": \"pound\", \"LBS\": \"pound\", \"Lb\": \"pound\", \"lB\": \"pound\", \"LB\": \"pound\", \"Lbs\": \"pound\",\n",
        "    \"mG\": \"milligram\", \"mg\": \"milligram\", \"MG\": \"milligram\",\n",
        "    \"mv\": \"millivolt\", \"MV\": \"millivolt\", \"Mv\": \"millivolt\", \"mV\": \"millivolt\",\n",
        "    \"kv\": \"kilovolt\", \"KV\": \"kilovolt\", \"Kv\": \"kilovolt\", \"kV\": \"kilovolt\",\n",
        "    \"v\": \"volt\", \"V\": \"volt\",\n",
        "    \"w\": \"watt\", \"W\": \"watt\", \"WATT\": \"watt\", \"Watt\": \"watt\",\n",
        "    \"kw\": \"kilowatt\", \"KW\": \"kilowatt\", \"Kw\": \"kilowatt\", \"kW\": \"kilowatt\",\n",
        "    \"ft³\": \"cubic foot\", \"FT³\": \"cubic foot\", \"Ft³\": \"cubic foot\", \"fT³\": \"cubic foot\",\n",
        "    \"µl\": \"microlitre\", \"µL\": \"microlitre\", \"ul\": \"microlitre\", \"uL\": \"microlitre\",\n",
        "    \"Cup\": \"cup\", \"cup\": \"cup\", \"CUP\": \"cup\",\n",
        "    \"fl oz\": \"fluid ounce\", \"FL OZ\": \"fluid ounce\", \"Fl Oz\": \"fluid ounce\", \"fl Oz\": \"fluid ounce\", \"FL Oz\": \"fluid ounce\", \"floz\": \"fluid ounce\",\n",
        "    \"cl\": \"centilitre\", \"CL\": \"centilitre\", \"Cl\": \"centilitre\",\n",
        "    \"gal\": \"gallon\", \"GAL\": \"gallon\", \"Gal\": \"gallon\", \"gAl\": \"gallon\",\n",
        "    \"pt\": \"pint\", \"PT\": \"pint\", \"Pt\": \"pint\",\n",
        "    \"dl\": \"decilitre\", \"DL\": \"decilitre\", \"Dl\": \"decilitre\",\n",
        "    \"ml\": \"millilitre\", \"ML\": \"millilitre\", \"Ml\": \"millilitre\", \"mL\": \"millilitre\",\n",
        "    \"qt\": \"quart\", \"QT\": \"quart\", \"Qt\": \"quart\",\n",
        "    \"in³\": \"cubic inch\", \"IN³\": \"cubic inch\", \"In³\": \"cubic inch\",\n",
        "    \"L\": \"litre\",\n",
        "    \"inch\": \"inch\", \"Inch\": \"inch\", \"INCH\": \"inch\", \"iNCH\": \"inch\", \"in\": \"inch\", \"IN\": \"inch\", \"iN\": \"inch\", \"In\": \"inch\", \"Inches\": \"inch\", '\"': \"inch\",\n",
        "}\n",
        "\n",
        "\n",
        "# Function to correct 'O' to '0' when it's the 4th character in numeric patterns\n",
        "def correct_o_to_0(text):\n",
        "    '''Corrects the character 'O' to '0' in numeric contexts, especially in the 4th position of numbers.'''\n",
        "    if not isinstance(text, str):\n",
        "        return text\n",
        "\n",
        "    # Regex to identify patterns where 'O' appears as the 4th character in a number like '140OmG'\n",
        "    corrected_text = re.sub(r'(\\d{3})O', r'\\g<1>0', text)\n",
        "\n",
        "    return corrected_text\n",
        "\n",
        "# Function to extract numbers with specified units\n",
        "def extract_numbers_with_units(text, units):\n",
        "    '''Extract numbers followed by specified units from the given text.'''\n",
        "    if not isinstance(text, str):\n",
        "        return ''\n",
        "\n",
        "    # Correct 'O' to '0' in the text\n",
        "    text = correct_o_to_0(text)\n",
        "\n",
        "    # Sort units by length in decreasing order to match longer units first\n",
        "    sorted_units = sorted(units, key=len, reverse=True)\n",
        "\n",
        "    # Create a regex pattern to match numbers with specified units\n",
        "    unit_pattern = '|'.join(re.escape(unit) for unit in sorted_units)\n",
        "\n",
        "    # Modified pattern: match numbers followed by units with or without spaces between them\n",
        "    pattern = rf'(\\d+(?:[Oo]\\d+)?(?:\\.\\d+)?(?:\\s*[-–—to]+\\s*\\d+(?:\\.\\d+)?)?)\\s*({unit_pattern})\\b'\n",
        "\n",
        "    # Find all matches of the pattern in the text (case-insensitive)\n",
        "    matches = re.findall(pattern, text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Process matches to handle ranges and format as \"number unit\"\n",
        "    results = []\n",
        "    for match in matches:\n",
        "        number_range, unit = match\n",
        "        # Handle cases where the unit is a quotation mark (for inches)\n",
        "        if unit in {'\\\\\"', '\"', \"'\", 'inches'}:\n",
        "            unit = 'inch'\n",
        "        # Replace 'to' or dashes with '-' for ranges\n",
        "        number_range = re.sub(r'\\s*(?:[-–—to]+)\\s*', '-', number_range)\n",
        "        # Remove any spaces in the number\n",
        "        number_range = number_range.replace(' ', '')\n",
        "\n",
        "        # Convert units using the unit conversion map\n",
        "        if unit in unit_conversion_map:\n",
        "            unit = unit_conversion_map[unit]\n",
        "\n",
        "        results.append(f'{number_range} {unit}')\n",
        "\n",
        "    # Join the results into a single string\n",
        "    return ', '.join(results)\n",
        "\n",
        "# Load the original CSV file with image names and detected text\n",
        "input_csv = r\"E:\\ML_challenge_DATASET\\TEST\\Test_data\\Detected_OCR\\Folder1_OCR.csv\"\n",
        "df = pd.read_csv(input_csv)\n",
        "\n",
        "# Create a new DataFrame to store results\n",
        "results_df = pd.DataFrame()\n",
        "\n",
        "# Extract numbers with units and create columns based on entity_unit_map\n",
        "for entity, units in entity_unit_map.items():\n",
        "    results_df[entity] = df['Detected Text'].apply(lambda text: extract_numbers_with_units(text, units))\n",
        "\n",
        "# Add the image name column and any additional columns from the original DataFrame\n",
        "results_df = pd.concat([df[['Image Name', 'Detected Text']], results_df], axis=1)\n",
        "\n",
        "# Save the results to a new CSV file\n",
        "output_csv = r\"E:\\ML_challenge_DATASET\\TEST\\Test_data\\Detected_OCR\\Folder1_OCR_CHECK.csv\"\n",
        "results_df.to_csv(output_csv, index=False)\n",
        "\n",
        "print(f'Results saved to {output_csv}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Merging Two CSV Files on Image Names:**\n",
        "\n",
        "*Libraries Used: pandas.*\n",
        "\n",
        "Process:\n",
        "1. Two CSV files are loaded: one with image links and entity names, the other with image names and detected text from OCR.\n",
        "2. The image name is extracted from the image link (assuming the file name is at the end of the URL).\n",
        "3. The two datasets are merged on the common field, 'Image Name', using a left join.\n",
        "4. The merged dataset is saved as a new CSV file, containing the image name, link, entity name, and OCR-detected text."
      ],
      "metadata": {
        "id": "fPQaQ-Tx0X3p"
      },
      "id": "fPQaQ-Tx0X3p"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64795bca-bdef-4347-95d1-cf0bd4717eb5",
      "metadata": {
        "id": "64795bca-bdef-4347-95d1-cf0bd4717eb5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the two CSV files\n",
        "csv1 = pd.read_csv(r\"C:\\Users\\ANNA MANI\\Downloads\\66e31d6ee96cd_student_resource_3\\student_resource 3\\dataset\\test.csv\")  # Contains index, image link, and entity name\n",
        "csv2 = pd.read_csv(r\"E:\\ML_challenge_DATASET\\TEST\\Check_detection\\DETECTION_2\\Folder10_OCR.csv\")  # Contains image names\n",
        "\n",
        "# Extract the image name from the image link in the first CSV (assuming image link contains file name at the end)\n",
        "csv1['Image Name'] = csv1['image_link'].apply(lambda x: x.split('/')[-1])\n",
        "\n",
        "# Merge the two CSVs based on the image name\n",
        "merged_csv = pd.merge(csv2, csv1, on='Image Name', how='left')\n",
        "\n",
        "# Save the merged data to a new CSV file\n",
        "merged_csv.to_csv(r\"E:\\ML_challenge_DATASET\\TEST\\Check_detection\\DETECTION_2\\Folder10_OCR_Merged.csv\", index=False)\n",
        "\n",
        "print(\"Merged CSV file saved successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Concatenating Multiple CSV Files:**\n",
        "\n",
        "*Libraries Used: pandas, os.*\n",
        "\n",
        "Process:\n",
        "1. The folder path containing multiple CSV files is provided.\n",
        "2. Each CSV file in the folder is read into a DataFrame and stored in a list.\n",
        "3. All DataFrames are concatenated into a single large DataFrame.\n",
        "4. The combined data from all CSV files can be processed or saved for further analysis."
      ],
      "metadata": {
        "id": "QRiitYIE0lSg"
      },
      "id": "QRiitYIE0lSg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c7338aa-ba44-4adc-9745-ef3f5978d215",
      "metadata": {
        "id": "1c7338aa-ba44-4adc-9745-ef3f5978d215"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Path to the folder containing the CSV files\n",
        "folder_path = r\"E:\\ML_challenge_DATASET\\TEST\\Check_detection\\DETECTION_2\\Merged\"\n",
        "# List to store dataframes\n",
        "dfs = []\n",
        "\n",
        "# Iterate through all CSV files in the folder\n",
        "for filename in sorted(os.listdir(folder_path)):\n",
        "    if filename.endswith('.csv'):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        # Read the CSV file into a DataFrame\n",
        "        df = pd.read_csv(file_path)\n",
        "        # Append DataFrame to list\n",
        "        dfs.append(df)\n",
        "\n",
        "# Concatenate all DataFrames in the list into one DataFrame\n",
        "merged_df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "# Sort by index column (assuming the index column is named 'Index')\n",
        "merged_df.sort_values(by='index', inplace=True)\n",
        "\n",
        "# Reset the index of the merged DataFrame\n",
        "merged_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Save the merged DataFrame to a new CSV file\n",
        "merged_df.to_csv(r\"E:\\ML_challenge_DATASET\\TEST\\Check_detection\\DETECTION_2\\Merged_OUTPUT.csv\", index=False)\n",
        "\n",
        "print(\"CSV files have been merged and saved successfully.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}